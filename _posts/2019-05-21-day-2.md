---
title:  Day 2
layout: singletrack
category: ds-advances19
tagline: 
show_abstracts: true
talks:
- title: "Arrivals"
  start: "8:00"
  end: "9:00"
<!-- 
- start: "9:00"
  end: "9:35"
  author:
  - given: Bennett
    family: Kleinberg
    institute: University College London
    url: https://bkleinberg.net/
  title: Will Crime Science eventually become Data Science?
  abstract: "Crime and security research is experiencing a push towards data science fueled by new challenges and stakeholder demand. With an increasing interest in understanding problems at scale and finding needles in haystacks, automated methods and data-driven approaches are embraced with the promise of solving long-standing and emerging problems. This talk will address the question of whether crime and security science will eventually become data science. It will outline ongoing work that harnesses data science for existing and emerging crime problems. The talk further discusses why we need to embrace data science and why we should cautious about doing so, and will highlight fallacies in the understanding of data science for crime science and provide an outlook on the merger of the disciplines."
- start: "9:40"
  end: "10:15"
  author:
  - given: Marion
    family: Oswald
    institute: University of Winchester
    url: https://www.winchester.ac.uk/about-us/leadership-and-governance/staff-directory/staff-profiles/oswald.php
  title: Old laws for new (algorithmic) tricks
  abstract: "This talk will consider some of the risks and challenges raised by the use of algorithm-assisted decision-making and predictive machine learning tools by the public sector, with a particular focus on policing and security. Alongside, it reviews a number of long-standing English administrative law rules designed to regulate the discretionary power of the state. The principles of administrative law are concerned with human decisions involved in the exercise of state power and discretion, thus offering a promising avenue for the regulation of the growing number of AI methods and applications deployed within the public sector. This talk will re-frame key rules for the new algorithmic environment and argues that 'old' law-interpreted for a new context-can help guide lawyers, data scientists and public sector practitioners alike when considering the development and deployment of new algorithmic tools."
- start: "10:20"
  title: Coffee
- start: "11:00"
  end: "11.35"
  author:
  - given: Paul
    family: Taylor
    institute: Lancaster University
    url: https://pauljtaylor.com/
  title: The Synergy of Behavioural and Data Science in Security
  abstract: "I will argue that recent advances in security data science have come not from statistical innovation but from innovation produced by behavioural theory. This is because the behavioural sciences have much to say about what to measure and how such measurement should be organised within data models. Behavioural science illuminates what predictors are useful, which makes tractable the statistical handling of complex social data. I will illustrate this behaviour—data science synergy by showing how research on insider threat derived a novel measure of social cohesion that differentiates insiders from their coworkers with greater accuracy than complex, mass-variable solutions. I will end by highlighting an enduring behavioural science problem in urgent need of some data science."
- start: "11:40"
  end: "11:55"
  author:
  - given: Lorenzo
    family: Cavallaro
    institute: Kings College London
    url: https://s2lab.kcl.ac.uk/
  title: "When the Magic Wears Off: Flaws in ML for Security Evaluations (and What to Do about It)"
  abstract: "Academic research on machine learning-based malware classification appears to leave very little room for improvement, boasting F1 performance figures of up to 0.99. Is the problem solved? In this talk, we argue that there is an endemic issue of inflated results due to two pervasive sources of experimental bias: spatial bias, caused by distributions of training and testing data not representative of a real-world deployment, and temporal bias, caused by incorrect splits of training and testing sets (e.g., in cross-validation) leading to impossible configurations. To overcome this issue, we propose a set of space and time constraints for experiment design. Furthermore, we introduce a new metric that summarizes the performance of a classifier over time, i.e., its expected robustness in a real-world setting. Finally, we present an algorithm to tune the performance of a given classifier. We have implemented our solutions in TESSERACT, an open source evaluation framework that allows a fair comparison of malware classifiers in a realistic setting. We used TESSERACT to evaluate two well-known malware classifiers from the literature on a dataset of 129K applications, demonstrating the distortion of results due to experimental bias and showcasing significant improvements from tuning."
- start: "12:00"
  end: "12:15"
  author:
  - given: Michael
    family: Smith
    institute: University of Sheffield
    url: http://www.michaeltsmith.org.uk
  title: Adversarial Vulnerability Bounds for Gaussian Process Classification
  abstract: "Machine learning (ML) classification is increasingly used in safety-critical systems. Protecting ML classifiers from adversarial examples (AEs) is crucial. In this paper we produce a bound that holds for the entire input domain, thus bounding the potential for any future adversarial method to cause misclassification. We use Gaussian process classification (GPC) due to its strong priors and uncertainty quantification and frame the problem as bounding the number of inputs that need perturbing to cause a confidently classified point to be confidently misclassified. 
We demonstrate the method produces practically useful bounds and investigate the effect of regularisation, comparing the results to logistic regression (LR). The method provides formal guarantees on the robustness of GPC."
- start: "12:20"
  title: Lunch
- start: "13:30"
  end: "14:05"
  author:
  - given: Silvia
    family: Chiappa
    institute: DeepMind
    url: https://csilviavr.github.io/
  title: Fair Machine Learning
  abstract: In this talk, I first will introduce fairness in machine learning using a causal Bayesian network viewpoint. I will then present our work on using counterfactual tools to alleviate fairness issues in complex scenarios, and explain an optimal way to achieve desired independence with respect to sensitive information.
- start: "14:10"
  end: "14:45"
  author:
  - given: Chris
    family: Williams
    institute: University of Edinburgh and Alan Turing Institute
    url: https://homepages.inf.ed.ac.uk/ckiw/
  title: Artificial Intelligence for Data Analytics
  abstract: "A common view is that up to 80% of work on a data mining project is involved in data understanding, cleaning and preparation, yet machine learning has not focused very much on these topics.  I will describe issues around data parsing, obtaining (or inferring) a data dictionary, data integration, entity resolution, structural variability, identifying and repairing missing data, and anomaly detection and repair. I will discuss work from the AIDA project at the Alan Turing Institute which addresses some of these issues.

Joint work with Taha Ceritli, James Geddes, Zoubin Ghahramani, Ernesto Jimenez-Ruiz, Ian Horrocks, Alfredo Nazabal, Tomas Petricek, Charles Sutton, and Gerrit Van Den Burg."
- start: "14:50"
  end: "15:05"
  author:
  - given: Reham
    family: Badawy
    institute: Aston University
    url: https://www2.aston.ac.uk/news/expert-directory/expert?id=98360016-3d2b-4d49-9832-01adb6afcec3
  title: Deconfounded Random Forests
  abstract: "Supervised learning algorithms, such as random forests or deep nets, &#34;are associational&#34; techniques that attempt to optimise their parameters to infer an input-output relationship from data. However, association does not imply causation, and thus they often fail to generalise depending upon the specific causal structure generating the data. Research in adversarial examples and simple innocuous perturbations in image recognition reflect this. With little integration of expert domain knowledge and information on the data generating process, they are blind to the wider causal structure in which the specific input-output relationship of interest is embedded. 

Often, the effects of confounders i.e. variables that cause 'false' associations, must be ‘blocked’ or ‘controlled’ for, as they prevent accurate assessment of the predictive accuracy of the supervised learning when the causal setting changes. This situation, in which the causal structure is different between training/test data and the population data, occurs in most practical settings, which means that supervised learning algorithms are often useless in practice, and cross-validated results are unreliable. 

While there exist numerous ways to remove or control confounding variables including randomisation, restriction and matching, these are only applicable at the time of study design. Often, a single experimental dataset is such that it is not possible to estimate the extent to which the supervised learning algorithm will generalize to different causal settings. 

We present a way to adapt one of the most sophisticated supervised learning algorithms - random forests - to detect confounding within the structure of the model after training, we call this the &#34;deconfounded random forest&#34;. We also show how to modify the training step of the random forest in order to minimize the effect of known confounders, without the need for classical deconfounding methods such as stratification, which often requires excessively large amounts of data and may not be feasible if certain variables were not measured when the data was generated. 

We demonstrate the performance of this new algorithm on synthetic data, and on a real-world example in health informatics from an experiment using smartphones where the confounding effect is particularly strong. This is a prevailing problem in health informatics since there exists a complex relationship between patient-specific characteristics to clinically relevant endpoints which may be confounded by biological variation, as well as social and environmental factors that obstruct the naïve supervised model’s ability to generalise to different causal settings."
- start: "15:10"
  title: Coffee
- start: "15:40"
  end: "15:55"
  title: Decomposing feature-level variation with Covariate Gaussian Process Latent Variable Models
  author: 
  - given: Kaspar
    family: M&#228rtens
    institute: University of Oxford
    url: http://csml.stats.ox.ac.uk/people/martens/
  abstract: "The interpretation of complex high-dimensional data typically requires the use of dimensionality reduction techniques to extract explanatory low-dimensional representations. However, these representations may not be sufficient or appropriate to aid interpretation, and in many real-world problems, the physical interpretation must be made in terms of the original features themselves. Therefore characterising the relationship between latent low-dimensional representations, external covariates, and feature-level variation can be critical. 

We propose to achieve this through the Covariate Gaussian Process Latent Variable Model (c-GPLVM) which embeds structured sparsity-inducing kernel decomposition within the GPLVM framework to allow the explicit disentanglement of feature-level variation in terms of covariate-dependent effects, contribution of latent variables, and interaction effects between the two. 

We demonstrate the utility of this model on a number of simulated examples and applications in disease progression modelling from high-dimensional gene expression data in the presence of additional phenotypes. In each setting we show that the c-GPLVM is able to effectively extract low-dimensional structures from high-dimensional data sets whilst allowing a breakdown of feature-level variability that is not present in other commonly used dimensionality reduction approaches. "
- start: "16:00"
  end: "16:15"
  title: "ANNABELL integrated in iCub: towards a grounded multi language system"
  author: 
  - given: Giovanni
    family: Masala
    institute: Manchester Metropolitan University
    url: https://www2.mmu.ac.uk/scmdt/staff/profile/index.php?id=4113
  abstract: "Linking neural network language systems to robotic platforms enables to tackle the language grounding problem [1]. The grounding problem is strictly connected to the embodied approach to cognition in both natural and artificial cognitive systems. The primary accounts of grounded cognition address the role of the body in cognition, based on prevailing findings that bodily states can bootstrap cognitive skills. We propose an integrated platform build upon a cognitive neuroscience-inspired system called ANNABELL [2] and the iCub robot [3]. The ANNABELL system (Artificial Neural Network with Adaptive Behaviour Exploited for Language Learning) provides a critical development in the qualitative and quantitative scaling-up of neural network models exploited for language learning and understanding. The aim is to effectively perform open-ended, cumulative learning experiments to validate the neuro-robotic architecture for human-robot scenarios on joint object manipulation tasks and on conversational interactions with robot companions. 
ANNABELL is a cognitive neural architecture designed to help comprehend the cognitive processes involved in early language development through a large-scale neural network (2.1 million neurons, interconnected through 33 billion virtual connections) capable of learning thousands of words and sentences. The architecture of ANNABELL finds a correspondence with the Baddeley’s multi-component working memory model [4] comprising four main components: a verbal short-term memory (STM), a verbal long-term memory, a central executive and a reward structure. 
To introduce the grounding in ANNABELL, a new visual content module — the visuo-spatial sketchpad of the Baddeley’s architecture — is under development. The integrated platform between ANNABELL and iCub, is achieved through a Yet Another Robot Platform (YARP) interface [6]. The YARP module provides the common communication interface between the robot, the novel version of the ANNABELL system and further additional features namely a smart vision module, based on a deep learning approach [7] and a speech recognition module, based on Google Cloud Speech, to insert input by speech instead of written text. "
- start: "16:20"
  end: "16.55"
  author:
  - given: Yiannis
    family: Demiris
    institute: Imperial College London
    url: https://www.imperial.ac.uk/people/y.demiris
  title: Machine Learning for personalisation in assistive robotics
  abstract: "Assistive Robots have great potential in empowering humans with increased capabilities but for assistance to be most effective, it should be personalised to the individual. Machine learning has great potential for personalisation through the acquisition of physiological, behavioural and performance data through sensors. In this talk, I will describe our computational architectures for biologically inspired action understanding and user modelling through generative ensembles of machine learning algorithms working at multiple levels of abstraction. I will describe a range of applications demonstrating the use of data-driven personalisation in fields such as robotic wheelchairs for children, assisted dressing, robot-assisted education and human-vehicle interaction."
- start: "17.00"
  title: Close
---



 -->
